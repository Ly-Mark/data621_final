---
author: Kimberley Chiu, Marc McCoy, Mark Ly
date: '`r format(Sys.Date())`'
title: The Impact of Socioeconomic Status and Education on the Incidence of Alzheimer's
  Disease
subtitle: Data 621 Winter 2022 Course Project
output:
  pdf_document:
    number_sections: true
    toc_depth: 2.0
    toc: true
  html_document: default
abstract: |
 
 
 
 
 
 
 
 \noindent \textbf{Background:} Noise, as the term itself suggests, is most often seen a nuisance to ecological insight, a inconvenient reality that must be acknowledged, a haystack that must be stripped away to reveal the processes of interest underneath. Yet despite this well-earned reputation, noise is often interesting in its own right: noise can induce novel phenomena that could not be understood from some underlying determinstic model alone.\break
 \noindent \textbf{Methods:} Nor is all noise the same, and close examination of differences in frequency, color or magnitude can reveal insights that would otherwise be inaccessible.\break
 \noindent \textbf{Results:} Yet with each aspect of stochasticity leading to some new or unexpected behavior, the time is right to move beyond the familiar refrain of "everything is important" (Bjørnstad & Grenfell 2001).  Stochastic phenomena can suggest new ways of inferring process from pattern, and thus spark more dialog between theory and empirical perspectives that best advances the field as a whole.\break
 \noindent \textbf{Conclusion:} I highlight a few compelling examples, while observing that the study of stochastic phenomena are only beginning to make this translation into empirical inference.  There are rich opportunities at this interface in the years ahead.\break
 \noindent Abstract word count: 350
 \noindent Manuscript word count: 1500
 \noindent Figures: 7 figures 
 \noindent Tables: 7 tables
 \noindent References: \newpage
fontsize: 11pt
# lof: true
# lot: true
---



\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE) 
library(dplyr)
library(readr)
library(ggplot2)
library(ggthemes)
library(flextable)
library(gridExtra)
library(naniar)
library(tidyr)
library(officer)
```

# Introduction: Noise the nuisance

To many, stochasticity, or more simply, noise,
is just that -- something which obscures patterns we are trying to infer (Knape & de Valpine 2011); and an ever richer batteries of statistical methods are developed largely in an attempt to strip away this undesirable randomness to reveal the patterns beneath (Coulson 2001).  Over the past several decades, literature in stochasticity has transitioned from thinking of stochasticity in such terms; where noise is a nuisance that obscures the deterministic skeleton of the underlying mechanisms, to the recognition that stochasticity can itself be a mechanism for driving many interesting phenomena (Coulson et al. 2004).  Yet this transition from noise the nuisance to noise the creator of ecological phenomena has had, with a few notable exceptions, relatively little impact in broader thinking about stochasticity.  One of the most provocative of those exceptions has turned the classical notion of noise the nuisance on its head: recognizing that noise driven phenomena can become a tool to reveal underlying processes: to become noise the informer.  Here I argue that this third shift in perspective offers an opportunity to better bridge the divide between respective primarily theoretical and primarily empirical communities by seeing noise not as mathematical curiosity or statistical bugbear, but as a source for new opportunities for inference.

# Methods

## Study Design

In arguing for this shift, it essential to recognize this is a call for a bigger tent, not for the rejection of previous paradigms.  What I will characterize as 'noise the nuisance' reflects a predominately statistical approach, in which noise, almost by definition, represents all the processes we are not interested in that create additional variation which might obscure the pattern of interest.  By contrast, an extensive literature has long explored how noise itself can create patterns and explain processes from population cycling to coexistence.  These broad categories should be seen as a spectrum and not be mistaken for either a sharp dichotomy nor a reference to a strictly empirical-theoretical divide.  Each paradigm expands upon rather than rejects the previous notion of noise: the recognition that noise can create novel phenomena does not mean that noise cannot also obscure the signal of some process of interest.  Likewise, seeking to use noise as a novel source of information about underlying processes will be informed by both previous paradigms, as our discussion will illustrate.


## Study population

The dataset contains 9 demographic, clinical and derived anatomic values for 150 patients. Originally, the dataset was from a longitudinal study however, we plan to use it for this for a logistic regression. To satisfy the independence assumption, we will only use information from the first visit in our analysis. Covariates include sex (M/F), age (60 - 96), years of education (6 - 23), social economic status (SES; ranked 1-5), mini-mental stat examination (MMSE), clinical dementia rating (CDR), estimated total intracranial volume (eTIV), atlas scaling factor (ASF), and normalized whole brain volume (nWBV). Each unique patient was grouped into one of three categories, Nondemented, Demented, and Converted. Subjects that did not have a SES value recorded (8) were excluded from this study. Outliers were identified by checking the distribution. Figure(#) shows the details of our screening and inclusion process. 



## Study Outcomes

### Primary Outcome

To emphasize the underlying trend in the changing roles in which we
see and understand noisy processes, I will also restrict my focus
to relatively simple models primarily from population ecology context.
Simplicity not only makes examples (in equations and in code) more
tractable but also allows us to focus on aspects that are germane to many
contexts rather than unique to particular complexities (Bartlett 1960; Levins
41 1966).

### Secondary Outcome

## Data collection and data source

The dataset we will be working with is from the Open Access Series of Imaging Studies (OASIS), which is a compilation of open-source distributing MRI datasets. OASIS is made available by the Washington University Alzheimer’s Disease Research Center. This dataset is licensed under the CCO 1.0 Universal (CCO 1.0) Public Domain Dedication and is open source where no research ethics approval is required. For the purposes of this project, we are assuming that the measurements all the measurements were taken at the end of the study.

The dataset can be obtained in a csv format that was read into R and analyzed using built-in packages in the R library. Columns for 'Hand','MRI.ID', 'Visit','Subject_ID' and, 'MR.Delay' were excluded from our study. All the patients were right hand and we are only considering the first visit for all the patients so 'Visit' and 'MR.Delay' are not needed. 'MRI.ID' and 'Subject_ID' are not informative so we excluded that column from our analysis. 

Using the _vis miss_ function from the visdat package in R, we created a heatmap to determine the percentage of missing data in each column. There are 8 missing values in the SES variable. Since SES cannot be determined on other values, we will remove the 8 individuals leaving us with 142 left for analysis. 

There are 14 patients in our dataset who under the _Converted_ group however we want to make our group variable a binary variable. We moved 14 patients in the _Converted_ group into the _Demented_. Finally we will convert the categorical columns of 'Group', 'sex' and 'SES' into factors, with 'Group' having two levels (Nondemented, Demented), 'sex' having 2 levels ('F','M'). 

From our exploratory analysis, we noticed that for the lowest SES level (5) only had 3 patients in total (1-Nondemented, 2-Demented). As a rule of thumb, we need at least 10 observations for each unique level to provide us with reasonable estimates and standard errors. We have chosen to collapse the lowest level of SES (5) to the second lowest (4) which adjust the SES covaraite to have 4 levels with 1 being the highest and 4 being the lowest.


```{r message = FALSE, warning = FALSE}
# Data wrangling
dementia <- read.csv("D:/UofC2022/Data621/Project/data621_final/Data/oasis_longitudinal.csv")

# selecting only first visit
dementia <- dementia[dementia$Visit == 1,]

# removing columns 
dementia <- dementia %>% 
  dplyr::select(-c(Hand,MRI.ID,Subject.ID,Visit,MR.Delay))


# Checking for missing data
vis_miss(dementia)

dementia_sub <- dementia %>% drop_na()

# moving converted
dementia_sub['Group'][dementia_sub['Group']=="Converted"] <- "Demented"

# rename columns
dementia_sub <- dementia_sub %>%
  rename(SEX = M.F)

# collapse levels
dementia_sub$SES <- replace(dementia_sub$SES, dementia_sub$SES == 5,4)

# creating factors
dementia_sub$SES <- factor(dementia_sub$SES)
dementia_sub$Group <- factor(dementia_sub$Group,levels=c("Nondemented",'Demented'))
dementia_sub$SEX <- factor(dementia_sub$SEX,levels=c("F",'M'))

head(dementia_sub)
```


## Statistical Methods

### Primary Outcome

We will be using logistic regression to answer our research question to determine the impact SES and education have on dementia. The reason we are using logistics regression for our analysis is due to our primary outcome, dementia, will be examined as a binary outcome of no dementia and dementia. 

### Secondary Outcome

We will examine any potential effect modifier 

### Tertiary Outcome

Ordinary logisitic regression with CDR of 0 0.5 and 1.0

### Software for Analysis

RStudio (Version 1.4.1717) was used to perform the data cleaning and statistical analysis on the relationship between dementia and age, considering potential confounding and effect modifiers. 

# Results

## Descriptive Statistics

The descriptive statistics for the potential predictors of dementia (n = 70) and nondemented (n = 72) for individuals between the ages of 60 - 96 years old can be found in the figure (#) using the _gtsummary_ package in R. The p-values reported in the figure are calculated for the Person's Chi-Squared test for categorical variables with expected cell counts $\geq 5$, Wilcoxon rank sum test for numerical variables and, a Fisher's exact test for categorical variables with an expected cell count $<5$. We used a significance level of $alpha=0.05$ to compare our findings. 

### Demographic variables

There were significantly more female participants in the nondementia group (69%) than the dementia group (49%, p-value = 0.011). The mean age of people who did not have dementia was 75 years old (sd = 8) which is exactly the same as those in the  dementia group (75 years old, sd =7; p-value = >0.9). The mean years of education were also the same in both the nondemented (15 years, sd = 3) and demented groups (14 years, sd = 3; p-value = 0.029).

We see high a higher proportion of participants with higher SES levels in the no dementia group (SES1 = 21%, SES2 = 38%) than in the dementia group (SES1 = 26%, SES2 = 21%, p-value = 0.3). While more participants in the dementia group were found to be in the lower SES levels (SES4 = 19%) compared to those in the no dementia group (SES4 = 27%, p-value = 0.3). 

### Derived Anatomic Values

The Estimated total intracranial volume (eTIV), Atlas scaling factor (ASF) and, Normalized whole brain volume (nWBV) mean values for both the non dementia group (eTIV = 1,480, sd = 184; p-value = 0.8, nWBV = 0.75, sd = 0.04; p-value = 0.002, ASF = 1.20, sd = 0.14; p-value = 0.8) and the dementia group (eTIV = 1,471, sd = 167; p-value = 0.8, nWBV = 0.73, sd = 0.03; p-value = 0.002, ASF = 1.21, sd = 0.13; p-value = 0.8).

```{r warning=FALSE} 
library(gtsummary)
dementia_descript <- subset(dementia_sub, select= -c(CDR))
dementia_descript %>%
  tbl_summary(
    by = Group,
    # sort = all_categorical()~'frequency',
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    missing_text = "(Missing)"
  ) %>%
  add_p()%>%
  modify_header(label = "**Variable**") %>% bold_labels()
```


## Primary Outcome Results (Logistic Regression)

### Variable selection

We selected our variables for our final model using a pairwise plot from GGAlly, vif function from the car and the backwards stepwise variable selection from the MASS package. From the pairwise plot, there are a few variables with high correlations which could indicate multicollinearity (eTIV & ASF). 

```{r message = FALSE, warning= FALSE}
library(GGally)
# no CDR
ggpairs(dementia_descript)
```
To check, we used the vif function on our full logistic model that incorporates all the predictors we want to examine. We see that ASF and eTIV both have a VIF value that is greater than 5. As a rule of thumb, VIF values that are greater than 5 have high collinearity and need to be addressed. ASF and eTIV both have high VIF values which are above 5.

We used the Akaike information criterion (AIC) to determine which predictors will be kept in our initial model. The model that provides the lowest AIC value will be the one that provides the best fit model with the least amount of variables to avoid over and under fitting. From the backwards stepwise regression our initial AIC was 141 from the full model but after dropping ASF, we obtain a AIC of 138.27. We can check this by doing a anova test with two models, one with ASF and a reduced one without.
```{r}
## Full model 
dem_fit <- glm(Group~SES + Age + EDUC +SEX +MMSE+ eTIV+nWBV+ASF, data=dementia_sub, family="binomial")
summary(dem_fit)
```

```{r}
## multicollinearity
car::vif(dem_fit)
```

```{r}
library(MASS)
# stepwise regression
dem_step <- dem_fit %>%
  stepAIC(direction='backward',trace = FALSE)
dem_step
```
To determine if we should drop the ASF variable, we can do partial F-test to determine of the is a difference between the two models at a significance level of $\alpha=0.05$. 

Our null hypothesis is that there is a there is no difference on coefficients if we remove them from our model and the alternative is that at least one of the coefficients removed from the model is non-zero 


$$H_o: \text{All coefficients removed from the model are zero}$$
$$H_a: \text{At least one of the coeffcients removed from the model is non-zero}$$

```{r}
anova(dem_step,dem_fit,test='Chisq')
```
We obtain a F test-statistic with df 1,131 and a p-value of 0.9287 which means we fail to reject the null hypothesis. This means we should drop the ASF coefficient because they do not significantly improve the fir of our model. 

#### Confounding

We expect there to be confounders in our dataset as they are linked to multiple risk factors associated with dementia. We expect age, sex, SES and, education all be confounders with dementia. From our stepwise model, the p-value for all of these co-variates are less than our significance level of $\alpha=0.05$, so we did not need to check for confounding by calculating the magnitude of confounding on our primary outcome. 

$$\text{Magnitude of Confoudning} = \frac{|\beta_{unadjusted}-\beta{adjusted}}{\beta_{adjusted}}$$
Ethnicity may have a confounding effect on the incidence of AD, however, we are unable to adjust for ethnicity since it is unmeasured in our dataset.


### Working model

Currently we have a multi-logistic model, from our stepwise selection, that is:

$$\hat{logit(p)} = \hat{\beta_0} + \hat{\beta_1}*\text{SES2} + \hat{\beta_2}*\text{SES3} + \hat{\beta_3}*\text{SES4}+ \hat{\beta_4}*\text{Age} + \hat{\beta_5}*\text{Educ}+ \hat{\beta_6}*\text{Males}+ \hat{\beta_7}*\text{MMSE}+ \hat{\beta_8}*\text{eTIV}+ \hat{\beta_9}*\text{nWBV} $$

$$\hat{logit(p)} = 54.04 - 1.857*\text{SES2} - 0.949*\text{SES3} - 2.477*\text{SES4}- 0.0968*\text{Age}- 0.2778*\text{Education}
+ 1.373*\text{Males}- 0.802*\text{MMSE}- 0.004296*\text{eTIV}- 21.551*\text{nWBV} $$
Where our baseline is women who are non-demented with the highest SES (SES=1). 

* Outcome: Dementia Status (Binary; Nondemented/Demented)

* Main Exposure: Social economic status (Ordinal; 1,2,3,4)

* Other Variables : Age(Continuous in years; 60 - 96); Education(Continuous in years; 6 - 23); Sex(Binary; Female/Male); MMSE (Continuous; 17-30); eTIV(Continuous in $mm^3$; 1123 - 1987); nWBV(Continuous in mg; 0.66 - 0.8370)


```{r}
summary(dem_step)
```
For this base model without effect modification we have:

* $\beta_0$ = 57.040: the log odds of dementia status of a female who with high SES when all other covariates are held at 0. However, this intercept does not make much sense as we cannot have an age or brain volumes of 0. 

* $\beta_1$ = the difference in log odd of dementia status between SES of 1 and SES 2 for females.
* $\beta_2$ = the difference in log odd of dementia status between SES of 1 and SES 3 for females.
* $\beta_3$ = the difference in log odd of dementia status between SES of 1 and SES 4 for females.
* $\beta_4$ = the change in log odds of dementia status for each 1 year increase in age for females with a SES of 1.
* $\beta_5$ = the change in log odds of dementia status for each 1 year increase in education for females with a SES of 1.
* $\beta_6$ = the difference of log odds of dementia status between females and males with a SES of 1 
* $\beta_7$ = the change in log odds of dementia status for ever 1 point increase in mini-mental state for females with a SES of 1. 
* $\beta_8$ = the change in log odds of dementia status for ever 1 unit increase in estimated total intracranial volume for females with a SES of 1. 
* $\beta_9$ = the change in log odds of dementia status for ever 1 unit increase in normalized whole brain volume for females with a SES of 1. 

To convert the log odds to an odds ratio, we will need to exponentiate our beta coefficients.

* $e^{-1.856}$ = 0.156 the odds ratio of SES switching from 1 to 2 is 0.156 () for  
* $e^{-0.949}$ = 0.387
* $e^{-2.477}$ = 0.0840
* $e^{-0.0968}$ = 0.9078 = For every one year increase in age, the odds of dementia is 0.9078 times larger for women in the highest SES
* $e^{-0.278}$ = 0.757
* $e^{1.37}$ = 3.95 = The odds of dementia for men is 3.95 times higher than for women at the highest SES level. 
* $e^{-0.802}$ = 0.448 = For every one point increase in MMSE, the odds of dementia is 0.488 times higher for women in the highest SES
* $e^{-0.00430}$ = 0.995 = For every 1 unit increase in eTIV, the odds of dementia is 0.995 times higher for women in the highest SES.
* $e^{-21.55}$ = 0.00

```{r}
# odds ratio
exp(coef(dem_step))

# 95% CI
exp(confint(dem_step))
```
```{r warning=FALSE, message =FALSE}
dem_tbl <- dem_step %>%
  tbl_regression(exponentiate = TRUE) %>%
  add_global_p()%>%
  bold_p()%>%
  add_vif()%>%
  modify_table_styling(
    columns = c(estimate, ci),
    rows = reference_row %in% TRUE,
    missing_symbol = "1.00"
  )
dem_tbl
```
### Goodness of fit


We can do a hypothesis test for the goodness of fit at the significance level of $\alpha=0.05$, where our null hypothesis is the the model is correct and the data fits. Our alternative hypothesis is that there is an evidence of a lack of fit.

$$H_o: \text{The data is a fits our selected model distrbution}$$

$$H_a: \text{The data is not consistent with our selected model distribution}$$

```{r}
1-pchisq(118.79,132)
```
With a Residual deviance of 118.79 on 132 degrees of freedom, we get a probability of 0.7882735, which is greater than our significance level of $\alpha=0.05$. We fail to reject our null hypothesis and we can say that our data is a good fit with our selected model. 

we tested our model using the following logistic regression assumptions:

### Linearity Assumption

The first assumption for logistic regression is that the relationship between X and the log-odds is linear. We can do this visually by plotting the continuous predictors and the logit of the outcome  and using the Box-Tidwell test and adding all the continuous co-varaites and their corresponding natural log. With an acceptance criteria of $\alpha=0.05$

#### Scatterplots

```{r}
dem_probs <- predict(dem_step,type = "response")
predicted.classes <- ifelse(dem_probs >0.5,'Nondemented','Demented')

dementia_num <- dementia_sub %>%
  dplyr::select_if(is.numeric)%>%
  dplyr::select(-c(CDR,ASF))

predictors <- colnames(dementia_num)

dementia_num <-dementia_num %>%
  mutate(logit = log(dem_probs/(1-dem_probs)))%>%
  gather(key="predictors",value='predictor.value',-logit)
```

```{r}
ggplot(dementia_num, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
```
From the graphs we see that MMSE, Education and nWBV are pretty linearly associated with the log-odds. Age does not look linear and might need to be transformed to a higher power (cubic)

#### Box-Tidwell

The Box-Tidwell test adds interactions between the continuous variables and the corresponding natural log into the model. Our null hypothesis is that the our continuous variables are linearly related to the log odds and the alternative hypothesis is that our continuous variables are not linearly related to the log odds. We will be using a significant level of $\alpha=0.05$.

$$H_o: \text{Continuous x variables are linearly related to the log-odds}$$

$$H_a: \text{Continuous x variables are not linearly related to the log-odds}$$

```{r}
library(car)
logodds <- dem_step$linear.predictors
boxTidwell(logodds~ dementia_sub$Age+dementia_sub$EDUC+dementia_sub$MMSE+dementia_sub$eTIV+dementia_sub$nWBV)
```

From the Box-Tidwell test, we see that the p-values for all of our continuous variables are greater than our significance level of $\alpha=0.05$ Since the p-values are not significant for all our continuous variables, we can say that our continuous x variables are linearly related to the log-odds.

### Multicollinearity
Multicollinearity was assessed earlier during during our variable selection. The presence of correlation can cause errors in our results by using redundant information. This could reduce our precision in our analysis. Running the VIF method again on our current model, we don't see any evidence of collinearity between any of our predictor variables.

```{r}
car::vif(dem_step)
```


### Influential Points and Outliers

To identify any outliers and influence point in our dataset, we will use boxplots, histograms and look at Cook's distance values. 

#### Boxplots

We can visually look for outliers using boxplots on our continuous variables. 
```{r}
dem_boxplot <- dementia_sub %>%
  dplyr::select(-c(CDR,ASF,SEX,SES))

```

```{r}
age_box <- ggplot(data = dem_boxplot[,c("Group",'Age')],aes(x=Group, y=Age))+
  geom_boxplot(aes(fill=Group),show.legend=FALSE)+
  xlab("")

educ_box <- ggplot(data = dem_boxplot[,c("Group",'EDUC')],aes(x=Group, y=EDUC))+
  geom_boxplot(aes(fill=Group),show.legend=FALSE)+
  xlab("")

mmse_box <- ggplot(data = dem_boxplot[,c("Group",'MMSE')],aes(x=Group, y=MMSE))+
  geom_boxplot(aes(fill=Group),show.legend=FALSE)+
  xlab("")

eTIV_box <- ggplot(data = dem_boxplot[,c("Group",'eTIV')],aes(x=Group, y=eTIV))+
  geom_boxplot(aes(fill=Group),show.legend=FALSE)+
  xlab("")

nWBV_box <- ggplot(data = dem_boxplot[,c("Group",'nWBV')],aes(x=Group, y=nWBV))+
  geom_boxplot(aes(fill=Group),show.legend=FALSE)+
  xlab("")

gridExtra::grid.arrange(age_box,educ_box,mmse_box,eTIV_box,nWBV_box,nrow=2,ncol=3)
```
We see that MMSE and eTIV both have outliers however, not all outliers are influential observations. To check if they are influential we will look at Cook's Distance measures. 

#### Cook's Distance

As a rule of thumb, if a point has a Cook's distance that is greater than 1, then the data point is likely to be influential. 

```{r}
plot(dem_step,pch=18,col='red',which=c(4))
```
From the plot, we see that the 3 highest values are from point 93 , 135 and 136. However, all 3 points have a Cook's distance that is less than 1 so we can leave them in our model. 


## Secondary Outcome Results (Effect modification/Confounding)

Using all the variables, we tested for effect modification between SES and nWBV and EDUC with nWVB. To test this we will do a likelihood ratio test without and without the interaction term to determine if we need to leave them in our model. The null hypothesis is that there is no difference between the models and our alternative hypothesis is that there is a difference between the two models. We will test this at a significance level of $\alpha=0.05$.

```{r}
#interaction age:SEX

summary(glm(Group~(SES + Age + EDUC +SEX +MMSE+ eTIV+nWBV)^2,  data=dementia_sub,
            family="binomial"))

inter<- glm(Group~SES + Age + EDUC +SEX + MMSE + eTIV +nWBV + nWBV*SES, data=dementia_sub, 
            family="binomial")

summary(inter)

nointer <- glm(Group~SES + Age + EDUC +SEX + eTIV+nWBV, data=dementia_sub, 
            family="binomial")

anova(nointer,inter,test='Chisq')
```



## Tertiary Outcome Results (Subgroup Analysis)


Demographic stochasticity refers to fluctuations in population sizes
or densities that arise from the fundamentally discrete nature of
individual birth and death events.  Demographic stochasticity is a
particularly instructive case for illustrating a mechanism for how
noise arises as an aggregate description from a lower-level mechanistic
process.  We summarize the myriad lower-level processes that
mechanistically lead to the event of a 'birth' in the population
as a probability: In a population of N identical individuals at
time t, a birth occurs with probability b_t(N_t) (_i.e._ a rate
that can depend on the population size, N), which increases the
population size to N+1. Similarly, death events occur with probability
d_t(N_t), decreasing the population size by one individual, to N-1.  Assuming
each of these events are independent, this is a state-dependent
Poisson process. The change in the probability of being in state
N is given by the sum over the ways to enter the state, minus the
ways to leave the state: a simple expression of probability balance
known as the master equation (Kampen 2007).  Note that in general
this approach is equally applicable to stochastic transitions of any sort,
not just step sizes of +/- 1 and not just birth and death events, but
can include transitions between stage classes or trait values, including
mutations to continuously-valued traits in evolutionary dynamics (e.g. Boettiger et al. 2010).

# Conclusion or Discussion
The  Gillespie (1977) provides an exact algorithmcfor simulating demographic stochasticity at an individual level.

# Contribution statement
The algorithm is a simple and direct implementation of the master equation, progressing in random step sizes determined by the waiting time until the next event. Free from both the approximations and mathematical complexity, the Gillespie algorithm is an interesting example of where we rely on a numerical implementation to check the accuracy of an analytic approximation, even in the case of simple models such as we will discuss.  Though the  algorithm is often maligned as numerically demanding, it can be run much more effectively even on large models on today's computers than when it was first developed in the 70s, and remains an underutilized approach for writing simple and approximation-free^[that is, free from the approximation made by SDE models as we see in the van Kampen example.  All models are, of course, only approximations.] stochastic ecological models.

# Table and Figures
As our objective is to tie the origins of noise more closely to biological
processes, it will be helpful to make the notion of a master equation concrete with a specific example.  We will focus on the classic case of Levins (1969) patch model, to illustrate the Gillespie algorithm and the van Kampen system size expansion

\begin{align}
\frac{\mathrm{d} n}{\mathrm{d} t} = \underbrace{c n \left(1 - \frac{n}{N}\right)}_{\textrm{birth}} - \underbrace{e n}_{\textrm{death}}, \label{levins}
\end{align}

# Appendix
where n individuals compete for a
finite number of suitable habitats N.  Individuals die a constant
rate e, and produce offspring at a constant rate c who then
have a probability of colonizing an open patch that is simply
proportional to the fraction of available patches, 1 - n/N.

```{r, fig.width=7,fig.height=5}
library(titanic)
data("titanic_train", package = "titanic")
titanic <- titanic_train
ggplot(data = titanic, aes(x = Fare))+ 
  geom_histogram()

```


Figure 1 shows the results of two exact SSA simulations of the classic patch model of Levins (1969).

# Conclusions

This review has explored three paradigms in how noise is viewed throughout the ecological literature, which I have dubbed respectively: noise the nuisance, noise the creator, and noise the informer.  Noise can be seen as a nuisance almost by definition: in examining the origins of noise, we have seen how stochasticity is introduced not because ecological processes are random in some fundamental sense, but rather, because those processes are influenced by a complex combination of forces we do not model explicitly.  In this view, noise captures all that additional variation that is separate from the process of interest, and a rich array of statistical methods allow us to separate the one from the other in observations and experiments.  By examining the origins of noise, we have seen that despite the complex ways in this noise can enter a model, that a Gaussian white-noise approximation (Kampen 2007; Black & McKane 2012) is often appropriate given a limit of a large system size -- a fact often invokedn implicitly but rarely derived explicitly from the theorems of Kurtz (1978) and others.\break

In this context, noise does not act to create phenomena of interest directly. The sudden transitions we seek to anticipate are still explained by the deterministic part of the model -- bifurcations. But nor is noise a nuisance that merely cloaks this deterministic skeleton from plain view: rather, it becomes a novel source of information that would be inaccessible from a purely deterministic approach.  I believe more examples of how noise can inform on underlying processes is possible, but will require greater dialog between these world views.


# Acknowledgements

The author acknowledges feedback and advice from the editor,
Tim Coulson and two anonymous reviewers. This work was supported in
part by  USDA National Institute of Food and Agriculture, Hatch
project CA-B-INS-0162-H.








# References





# Figure 1: Population dynamics from a Gillespie simulation of the Levins model with large (N=1000, panel A) and small (N=100, panel B) number of sites (blue) show relatively weaker effects of demographic noise in the bigger system. Models are otherwise identical, with e = 0.2 and c = 1 (code in appendix A). Theoretical predictions for mean and plus/minus one standard deviation shown in horizontal re dashed lines.
